import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms


class DataHolder:
    def __init__(self):
        self.train_holder = None
        self.test_holder = None
        self.height = None
        self.width = None

    def load_datasets(self):
        self.train_holder = DataLoader(
            datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor()), shuffle=True)
        _, self.height, self.width = self.train_holder.dataset.data.shape


class VAE:
    def __init__(self, vae_model, data_holder, optimizer):
        self.vae_model = vae_model
        self.data_holder = data_holder
        self.optimizer = optimizer(vae_model.parameters(), lr=1e-2)

    def train(self, epochs):
        self.vae_model.train()
        for epoch in range(epochs):
            losses = []
            for batch_id, (x_batch, _) in enumerate(self.data_holder.train_holder):
                self.optimizer.zero_grad()
                loss = self.vae_model(x_batch, self.__loss_func)
                loss.backward()
                self.optimizer.step()
                losses.append(loss.detach())
            print(
                f"===> Epoch: {epoch+1}/{epochs}, " +
                f"Avg Train Loss: {torch.tensor(losses).mean() / len(self.data_holder.train_holder.dataset):.3f}")

    def __loss_func(self, x, x_pred, mu_z, log_sigma_z):
        """
        VAE loss function = kl + reconstruct
            kl: KL between multivariate gaussian and standard multivariate gaussian.
            reconstruct: reconstruction the image generated by the decoder and the original one.
        """
        kl = 0.5 * torch.sum(torch.exp(log_sigma_z) + torch.pow(mu_z, 2) - 1 - log_sigma_z)
        binary_cross_entropy = torch.nn.BCELoss(reduction='sum')
        x_orig = x.view(-1, self.data_holder.height * self.data_holder.width).repeat(x_pred.size(0), 1)
        reconstruct = binary_cross_entropy(x_pred, x_orig)
        return reconstruct + kl
