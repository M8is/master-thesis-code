import torch


class LossHolder:
    def __init__(self):
        self.train_loss = []
        self.test_loss = []

    def add(self, train_loss, test_loss):
        self.train_loss.append(train_loss)
        self.test_loss.append(test_loss)

    def as_numpy(self):
        with torch.no_grad():
            train_loss = torch.stack(self.train_loss)
            test_loss = torch.stack(self.test_loss)
            return train_loss.numpy(), test_loss.numpy()


class VAE:
    def __init__(self, vae_model, data_holder, optimizer, learning_rate):
        self.vae_model = vae_model
        self.data_holder = data_holder
        self.optimizer = optimizer(vae_model.parameters(), lr=learning_rate)

    def train_epoch(self):
        train_losses = []
        test_losses = []
        for batch_id, (x_batch, _) in enumerate(self.data_holder.train_holder):
            self.vae_model.train()
            self.optimizer.zero_grad()
            params, x_preds = self.vae_model(x_batch)
            losses = self.__loss_func(x_batch, x_preds, *params)
            self.vae_model.backward(losses)
            self.optimizer.step()
            train_losses.append(losses.detach().mean())
            test_losses.append(self.test_epoch().mean())
        return torch.tensor(train_losses, requires_grad=False), torch.tensor(test_losses, requires_grad=False)

    def test_epoch(self):
        self.vae_model.eval()
        test_losses = []
        i = 0
        for x_batch, _ in self.data_holder.test_holder:
            params, x_preds = self.vae_model(x_batch)
            losses = self.__loss_func(x_batch, x_preds, *params)
            test_losses.append(losses.detach().mean())

            i += 1
            if i >= 100:
                break
        return torch.tensor(test_losses, requires_grad=False)

    def __loss_func(self, x, x_pred, mu_z, log_sigma_z):
        """
        VAE loss function = reconstruct + kl
            reconstruct: reconstruction the image generated by the decoder and the original one.
            kl: KL between multivariate gaussian and standard multivariate gaussian.
        """
        kl = 0.5 * torch.sum(torch.exp(log_sigma_z) + torch.pow(mu_z, 2) - 1 - log_sigma_z)
        # Use no reduction to get separate losses for each image
        binary_cross_entropy = torch.nn.BCELoss(reduction='none')
        x_orig = x.view(-1, self.data_holder.height * self.data_holder.width)
        reconstruct = binary_cross_entropy(x_pred, x_orig.repeat(x_pred.size(0), 1, 1)).mean(dim=2)
        return reconstruct + kl
